<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test Conversation History</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .test-section {
            background: white;
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        h2 {
            color: #333;
            margin-top: 0;
        }
        .code-block {
            background: #f0f0f0;
            border: 1px solid #ddd;
            border-radius: 4px;
            padding: 10px;
            margin: 10px 0;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            overflow-x: auto;
        }
        .success {
            color: #22c55e;
            font-weight: bold;
        }
        .error {
            color: #ef4444;
            font-weight: bold;
        }
        button {
            background: #3b82f6;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 16px;
        }
        button:hover {
            background: #2563eb;
        }
        .result {
            margin-top: 20px;
            padding: 15px;
            background: #f9fafb;
            border-radius: 6px;
            border: 1px solid #e5e7eb;
        }
    </style>
</head>
<body>
    <h1>Wine Expert - Conversation History Test</h1>
    
    <div class="test-section">
        <h2>Test Setup</h2>
        <p>This page tests the conversation history functionality. The chat system should now pass the full conversation history to the LLM on each request.</p>
        
        <h3>How it works:</h3>
        <ol>
            <li>User messages and Wine Expert responses are stored in the messages array</li>
            <li>When sending a new message, buildConversationHistory() extracts user/assistant messages</li>
            <li>The full history is passed to the LLM along with the current message</li>
            <li>This allows the AI to maintain context across the entire conversation</li>
        </ol>
    </div>

    <div class="test-section">
        <h2>Implementation Details</h2>
        
        <h3>1. Building Conversation History (chat.js)</h3>
        <div class="code-block">
buildConversationHistory() {
    const history = [];
    
    // Filter out system messages and build history
    for (const msg of this.app.messages) {
        if (msg.sender === 'User') {
            history.push({
                role: 'user',
                content: msg.content
            });
        } else if (msg.sender === 'Wine Expert') {
            history.push({
                role: 'assistant', 
                content: msg.content
            });
        }
        // Skip system messages
    }
    
    return history;
}
        </div>

        <h3>2. Updated API Call Flow</h3>
        <div class="code-block">
// Build conversation history from messages
const conversationHistory = this.buildConversationHistory();

// Call provider-specific method with history
switch(this.app.selectedProvider) {
    case 'google':
        response = await this.app.aiModels.callGoogleAPIWithHistory(
            systemPrompt, userInput, conversationHistory
        );
        break;
    // ... other providers
}
        </div>

        <h3>3. Provider Implementation Example (models.js)</h3>
        <div class="code-block">
async callOpenAIAPIWithHistory(systemPrompt, userPrompt, conversationHistory) {
    const messages = [
        { role: 'system', content: systemPrompt },
        ...conversationHistory,  // Full history
        { role: 'user', content: userPrompt }  // Current message
    ];
    
    // Make API call with complete message history
    return this.makeAPICall(...);
}
        </div>
    </div>

    <div class="test-section">
        <h2>Test Scenarios</h2>
        
        <h3>Scenario 1: Multi-turn Conversation</h3>
        <p>User uploads wine image → Gets analysis → Asks follow-up questions</p>
        <ul>
            <li>Turn 1: "Analyze this wine menu" (with image)</li>
            <li>Turn 2: "Which wine would pair best with salmon?"</li>
            <li>Turn 3: "What about the second wine you mentioned?"</li>
        </ul>
        <p>Expected: AI maintains context and remembers previous wines discussed</p>

        <h3>Scenario 2: Reference Previous Messages</h3>
        <ul>
            <li>Turn 1: "Tell me about Pinot Noir"</li>
            <li>Turn 2: "Compare it to Merlot"</li>
            <li>Turn 3: "Which one did you say was lighter?"</li>
        </ul>
        <p>Expected: AI can reference its previous responses</p>

        <h3>Scenario 3: Wine List Context + History</h3>
        <ul>
            <li>Turn 1: Upload wine list image</li>
            <li>Turn 2: "Which wines are under $50?"</li>
            <li>Turn 3: "Of those, which did you rate highest?"</li>
        </ul>
        <p>Expected: AI uses both wine list data and conversation history</p>
    </div>

    <div class="test-section">
        <h2>Verification Steps</h2>
        <ol>
            <li>Open the Wine Expert application</li>
            <li>Open browser console (F12)</li>
            <li>Start a conversation with multiple turns</li>
            <li>Look for console logs showing:
                <ul>
                    <li>"=== Conversation History ===" with message count</li>
                    <li>The full history array being passed</li>
                    <li>API request bodies containing all messages</li>
                </ul>
            </li>
            <li>Verify the AI maintains context across messages</li>
        </ol>
    </div>

    <div class="test-section">
        <h2>Benefits</h2>
        <ul>
            <li class="success">✓ Natural conversational flow</li>
            <li class="success">✓ AI remembers what was discussed</li>
            <li class="success">✓ Can reference previous messages</li>
            <li class="success">✓ Better context for follow-up questions</li>
            <li class="success">✓ More coherent multi-turn conversations</li>
        </ul>
    </div>

    <div class="test-section">
        <h2>Technical Notes</h2>
        <ul>
            <li>Google's API uses a different format - conversation is serialized into a single prompt</li>
            <li>OpenAI, xAI, and DeepSeek use the standard messages array format</li>
            <li>System messages are excluded from history (they're UI indicators, not conversation)</li>
            <li>Wine list context is still passed in the system prompt for reference</li>
            <li>Both conversation history AND wine data provide full context</li>
        </ul>
    </div>
</body>
</html>